### 1.Kubernetes简介

#### 1.1 Kubernetes是什么

1. Kubernetes，简称k8s，是用8代替八个字符"ubernete"而成的缩写；
2. Kubernetes是一个开源的容器编排引擎，用来对容器化应用进行自动化部署、扩缩和管理，Kubernetes的目标是让部署容器化的应用简单并且高效；
3. Kubernetes是一个可移植、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。它还拥有一个庞大且快速增长的生态系统，Kubernetes的服务、支持和工具广泛可用。

#### 1.2 应用部署方式的演进

![container](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210301114626.jpg) 

##### 传统部署时代：

早期，各个组织机构在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配的问题。例如，如果多个应用程序在一个物理服务器上运行，那么在某些实例中，一个应用程序可能会占用大部分资源，从而导致其他应用程序的性能不佳。

解决这个问题的方案是在不同的物理服务器上运行每个应用程序。但是由于资源利用不足而无法扩展， 并且维护许多物理服务器的成本很高。

##### 虚拟化部署时代：

为了解决传统部署方式带来的问题，引入了虚拟化。虚拟化技术允许你在单个物理服务器的CPU上运行多个虚拟机（VM）。 虚拟化可以实现应用程序在虚拟机之间的隔离，并在一个应用程序的信息不能被另一个应用程序自由访问的情况下提供一定的安全级别。

虚拟化技术能够更好地利用物理服务器上的资源，并具有更好的可伸缩性，因为应用程序可以很容易地添加或更新，降低硬件成本等等，通过虚拟化，你可以将一组物理资源表示为一次性虚拟机集群。

每个VM都是一台完整的机器，在虚拟硬件之上运行所有组件，包括它自己的操作系统。

##### 容器部署时代：

容器类似于VM，但是它们放宽了隔离属性，以便在应用程序之间共享操作系统（OS）。因此，容器被认为是轻量级的。与VM类似，容器有自己的文件系统、CPU、内存、进程空间等等。由于它们与底层基础架构分离，因此可以跨云和OS发行版本进行移植。

容器之所以变得流行，是因为它具有很多优秀，比如：

- 应用程序创建和部署的敏捷性：与使用VM镜像相比，容器镜像的创建更加简单和高效；
- 持续开发、集成和部署：通过快速有效的回滚(由于镜像的不可变性)，提供可靠和频繁的容器镜像构建和部署；
- 关注开发与运维的分离：在构建/发布时(而不是在部署时)创建应用程序容器镜像，从而将应用程序与基础架构分离；
- 可观察性：不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号；
- 跨开发、测试和生产的环境一致性：在便携式计算机上运行与在云中运行相同；
- 跨云和操作系统发行版本的可移植性：可在Ubuntu、RHEL、CoreOS、本地、Google Kubernetes Engine和其他任何地方运行；
- 以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行OS到使用逻辑资源在OS上运行应用程序；
- 松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分，并且可以动态部署和管理，而不是在一台大型单机上整体运行；
- 资源隔离：可预测的应用程序性能；
- 资源利用：高效率和高密度。

#### 1.3 Kubernetes的作用

容器是打包和运行应用程序的良好方式。在生产环境中，我们需要管理运行应用程序的容器，并确保不会出现停机。假设一个容器发生了故障，则需要启动另一个容器，如果能够通过系统自动完成该操作，就会变得更容易。而Kubernetes就可以解决这一问题。

Kubernetes为我们提供了一个灵活运行分布式系统的框架。它负责应用程序的扩展和故障转移，提供部署模式等。例如，Kubernetes可以轻松地管理系统的Canary部署。

Kubernetes可以为我们提供以下功能：

- **批处理**

  Kubernetes可以提供一次性任务、定时任务，满足批量数据处理和分析的场景。

- **服务发现和负载均衡**

  Kubernetes可以使用DNS名称或自己的IP地址公开容器。如果进入到容器的流量很高，Kubernetes能够负载平衡并分发网络流量，从而使部署稳定。

- **存储编排**

  Kubernetes允许我们自动挂载我们选择的存储系统，例如本地存储、公共云提供商等等。

- **自动部署和回滚**

  我们可以使用Kubernetes为部署的容器描述所需的状态，它可以以可控的速度将实际状态更改为所需状态。例如，我们可以自动化Kubernetes为我们的部署创建新的容器，删除现有的容器并将其所有资源用到新容器中。

- **自动装箱**

  假设为Kubernetes提供了一个节点集群，Kubernetes可以使用这些节点来运行容器化的任务。告诉Kubernetes每个容器需要多少CPU和内存(RAM)。Kubernetes可以将容器放到我们的节点上，并充分利用我们的资源。

- **自我修复**

  Kubernetes会重启失败的容器、替换容器、杀死不响应用户定义的健康检查的容器，并且在它们准备好提供服务之前不会将它们通告给客户端。

- **密钥与配置管理**

  Kubernetes允许我们存储和管理敏感信息，例如密码、OAuth令牌和SSH密钥。我们可以在不重建容器镜像的情况下部署和更新密钥以及应用程序配置，也无需在堆栈配置中暴露密钥。

#### 1.4 Kubernetes的架构

当我们部署完Kubernetes, 即拥有了一个完整的集群。一个Kubernetes集群由一组被称作节点的机器组成。这些节点上运行着Kubernetes所管理的容器化应用。集群应至少拥有一个工作节点。

##### 1.4.1 Kubernetes的集群节点

- **Master Node**

  该节点是Kubernetes的集群控制节点，对集群进行调度管理，接受集群外用户到集群的操作请求。Master Node由==API Server==、==Scheduler==、==etcd==、==Controller-Manager==组成。

- **Worker Node**

  该节点是集群的工作节点，节点上运行着用户的业务应用容器。Worker Node包括==kubelet==、==kube-proxy==以及容器运行环境(==Container Runtime==)，比如docker就是一种容器运行环境。

##### 1.4.2 Kubernetes架构图

以下是Kubernetes的架构图：

![k8s架构图](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210302094338.jpg) 

上图中涉及到的各个组件的含义，下文会有详细讲解。

### 2.Kubernetes集群的搭建

#### 2.1 前置知识点

目前生产部署Kubernetes集群主要有两种方式：

- **kubeadm**

  Kubeadm是一个Kubernetes部署工具，提供`kubeadm init`和`kubeadm join`来快速部署Kubernetes集群。具体详情也可以访问[官方地址](https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/)。

- **二进制包**

  我们可以从github下载发行版的二进制包，手动部署每个组件，组成Kubernetes集群。

> Kubeadm方式降低了部署的门槛，但屏蔽了很多细节，遇到问题很难排查。如果想要更加可控，还是推荐使用二进制包方式部署Kubernetes集群，虽然手动部署麻烦点，但是期间可以学习到很多的工作原理，也利于后期维护。

#### 2.2 kubeadm方式搭建k8s集群(单master)

kubeadm是官方社区推出的一个用于快速部署k8s集群的工具，这个工具能通过两条指令完成一个k8s集群的部署：

1. 使用`kubeadm init`创建一个Master节点；
2. 使用`kubeadm join <Master节点的IP和端口>`将Node节点加入到当前集群中。

##### 2.2.1 安装要求

- 一台或多台机器，操作系统为CentOS7；

- 硬件配置：2GB或更多RAM，2个CPU或更多CPU；

- 集群中所有机器之间网络互通；

- 可以访问外网，因为需要联网拉取镜像；

- 需要禁止swap分区。

##### 2.2.2 最终目标

1. 在所有节点上安装Docker和kubeadm；
2. 部署Kubernetes Master；
3. 部署容器网络插件；
4. 部署Kubernetes Node，将节点加入到Kubernetes集群中；
5. 部署Dashboard Web页面，可视化查看Kubernetes资源。

##### 2.2.3 主机规划

| 角色   | IP            |
| ------ | ------------- |
| master | 192.168.68.11 |
| node1  | 192.168.68.12 |
| node2  | 192.168.68.13 |

##### 2.2.4 系统初始化

###### 2.2.4.1 关闭防火墙

```shell
#临时关闭
systemctl stop firewalld

#永久关闭
systemctl disable firewalld
```

###### 2.2.4.2 关闭 selinux

```shell
#临时关闭
setenforce 0

#永久关闭
sed -i 's/enforcing/disabled/' /etc/selinux/config
```

###### 2.2.4.3 关闭swap

```shell
#临时关闭
swapoff -a

#永久关闭
sed -ri 's/.*swap.*/#&/' /etc/fstab 
```

###### 2.2.4.4 设置主机名

```shell
#在192.168.68.11主机上执行以下命令
hostnamectl set-hostname master

#在192.168.68.12主机上执行以下命令
hostnamectl set-hostname node1

#在192.168.68.13主机上执行以下命令
hostnamectl set-hostname node2
```

###### 2.2.4.5 在master中添加hosts

```shell
cat >> /etc/hosts << EOF
192.168.68.11 master
192.168.68.12 node1
192.168.68.13 node2
EOF
```

###### 2.2.4.6 将桥接的IPv4流量传递到iptables的链

```shell
cat > /etc/sysctl.d/k8s.conf << EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

#生效命令
sysctl --system
```

###### 2.2.4.7 时间同步

```shell
yum install -y ntpdate
ntpdate -u time.windows.com
```

> **注意**：以上系统初始化涉及到的命令，如无特殊说明，均需在所有主机上执行。

##### 2.2.5 安装Docker、kubeadm、kubelet

Kubernetes默认的容器运行环境为docker，因此要先安装Docker。我这边所有的主机上之前都安装过docker了，所以docker的安装这里就不再进行介绍了。

###### 2.2.5.1 添加阿里云YUM软件源

```shell
#对所有主机执行以下操作命令
cat > /etc/yum.repos.d/kubernetes.repo << EOF
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
```

###### 2.2.5.2 安装kubeadm，kubelet和kubectl

由于版本更新频繁，所以这里指定版本号进行安装部署：

```shell
#对所有主机执行安装命令
yum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0

#对所有主机执行以下命令，让kubelet开机启动
systemctl enable kubelet
```

##### 2.2.6 部署Kubernetes Master

```bash
#在master主机上执行以下命令
kubeadm init --apiserver-advertise-address=192.168.68.11 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.18.0 --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16
```

**命令中的参数含义如下：**

![kubeadm-init](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210304172944.png)    

命令的执行需要一段时间(期间可以重新开个窗口，使用`docker images`查看镜像下载的情况)，当出现如下内容时，说明已经执行成功了。

![image-20210302154448491](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210302154452.png)  

这个图中也有接下来需要我们执行的步骤，这些步骤下面也会说到。

==注意==：执行上面的`kubeadm init`那一长串命令的时候，也有可能会报下面的错：

![image-20210305220911407](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210305221028.png) 

如果真的报上图的错的话，依次执行以下命令后重启主机，然后再次执行`kubeadm init`那一长串命令即可。

```shell
#先使用cat命令查看ip_forward的值是否为0，如果为0就继续执行下面的命令
cat /proc/sys/net/ipv4/ip_forward

#上面的值如果为0的话，这里给改成1即可
echo "1" > /proc/sys/net/ipv4/ip_forward

#重启网络服务
service network restart

#最后为了保险起见，可以使用reboot命令重启主机
reboot
```


> 由于默认拉取镜像的地址(k8s.gcr.io)国内无法访问，所以`kubeadm init`命令后面的image-repository参数的值使用的是阿里云镜像仓库地址。

**使用kubectl工具：**

```shell
#在master节点依次执行以下命令
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

上面的命令执行完成之后，我们也可以通过`kubectl get nodes`命令进行查看，会显示如下内容：

```shell
AME     STATUS     ROLES    AGE   VERSION
master   NotReady   master   11m   v1.18.0
```

##### 2.2.7 加入Kubernetes Node

```shell
#在每个worker node主机上执行以下命令，每个人的这个命令都是不一样的，我们在执行完kubeadm init命令后，会输出下面这个命令，直接复制即可
kubeadm join 192.168.68.11:6443 --token ba295y.k5pqeuidfvqrrx2x \
    --discovery-token-ca-cert-hash sha256:0b7edbb6ebe7adf0a67f6a5ec7b8d8493263440f406628327800d9bafbe6c4f9
```

==注意==：在执行`kubeadm join`命令的时候，如果也出现执行`kubeadm init`命令时候的错误，那就还是按照上面提到的解决方案进行解决即可。

以上命令的token默认有效期为24小时，当过期之后，该token就不可用了。如果需要重新创建token，操作如下：

```shell
#在master节点执行以下命令
kubeadm token create --print-join-command

#我们也可以在master节点执行以下命令来查看token信息
kubeadm token list
```

当我们使用`kubeadm join`命令向集群中加入新节点后，在master主机上再次使用`kubectl get nodes`命令，可以发现节点已经添加成功了，如下所示：

```shell
NAME     STATUS     ROLES    AGE   VERSION
master   NotReady   master   44m   v1.18.0
node1    NotReady   <none>   15m   v1.18.0
node2    NotReady   <none>   14m   v1.18.0
```

##### 2.2.8 部署CNI网络插件

```shell
#我们可以使用如下命令来部署CNI网络插件(以下命令要在master主机执行)
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
```

如果出现"Unable to connect to the server"错误，那说明该地址已经被墙了，如果不知道怎么科学上网的话，可以使用如下命令获取并执行我翻墙下载的这个配置文件：

```shell
#在master主机上下载压缩包
wget https://files.cnblogs.com/files/gongcqq/kube-flannel.tar.gz

#解压压缩包，以便获取kube-flannel.yml文件
tar -zxvf kube-flannel.tar.gz

#执行kube-flannel.yml文件。如果网络环境不好，可以按照下面"注意事项"中把相关镜像先下载下来，再执行该文件
kubectl apply -f kube-flannel.yml
```

以上命令执行完成之后，再在master主机使用`kubectl get nodes`命令进行查看，发现节点状态都从之前的==NotReady==变成了==Ready==，如下所示：

```shell
NAME     STATUS   ROLES    AGE    VERSION
master   Ready    master   139m   v1.18.0
node1    Ready    <none>   110m   v1.18.0
node2    Ready    <none>   110m   v1.18.0
```

我们也可以在master主机上使用`kubectl get pods -n kube-system`命令查看pod的运行情况，查询结果如下：

![image-20210302174746085](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210302174748.png) 

**注意事项**：上面在使用`kubectl apply -f kube-flannel.yml`命令的时候会拉取一个flannel镜像，如果网络环境不好，可能会导致拉取失败，从而导致集群部署失败。我这边已经将该镜像打成了名为[flannel-v0.13.1-rc2.tar](https://gongsl.lanzous.com/iYJpGmkeiaj)的tar包，我们可以下载下来通过ftp的方式传到集群的各个主机上，假设都传到了主机的"/root"目录下，那么直接使用如下命令还原镜像即可：

```shell
docker load -i /root/flannel-v0.13.1-rc2.tar
```

##### 2.2.9 测试kubernetes集群

在Kubernetes集群中创建一个pod，验证是否正常运行：

```shell
#在master主机上创建并运行一个pod
kubectl create deployment nginx --image=nginx

#暴露端口
kubectl expose deployment nginx --port=80 --type=NodePort
```

以上命令执行完成之后，我们可以通过`kubectl get pod,svc`命令查看pod的运行情况：

![image-20210302181219698](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210302181739.png) 

由上图可知，刚才创建的pod正在运行中，且nginx暴露给外部访问的端口是**30412**，如果在浏览器中使用集群中任何一个主机加这个端口都能访问到nginx的话，就说明集群搭建成功了。我使用集群中的三个主机加上端口分别进行了访问，都是可以访问到nginx的，说明kubernetes集群搭建成功了。

```bash
http://192.168.68.11:30412
http://192.168.68.12:30412
http://192.168.68.13:30412
```

![image-20210302182217942](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210302182224.png) 

##### 2.2.10 部署Dashboard Web页面

**注意**：部署Dashboard Web页面章节涉及的所有命令均是在master节点上执行的。

1. 获取recommended.yaml文件

```shell
#可以使用如下命令进行下载
wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml
```

以上地址如果访问不了的话，可以使用如下方式下载：

```shell
#下载recommended.yaml的压缩包
wget https://files.cnblogs.com/files/gongcqq/recommended.tar.gz

#解压压缩包以获取recommended.yaml文件
tar -zxvf recommended.tar.gz
```

默认Dashboard只能集群内部访问，修改Service为NodePort类型，暴露到外部：

![image-20210306004457104](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210306004502.png) 

> **注意**：如果是通过上面第二个地址中的recommended.tar.gz获取到的recommended.yaml文件的话，就不用再增加NodePort类型了，因为压缩包中的recommended.yaml文件是已经增加过的。

2. 执行recommended.yaml文件

```shell
kubectl apply -f recommended.yaml
```

执行完成后，可以通过`kubectl get pods -n kubernetes-dashboard`命令进行状态查看，下图就是正常状态：

![image-20210306004943314](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210306004947.png) 

3. 创建用户并生成token

```shell
#创建用户
kubectl create serviceaccount dashboard-admin -n kube-system

#用户授权
kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin

#生成用户token
kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk '/dashboard-admin/{print $1}')
```

下图就是用户的token信息：

![image-20210306005317155](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210306005320.png) 

4. 登录Dashboard页面

浏览器输入集群中任一主机ip加30001端口都可访问到Dashboard页面，这里以master主机为例，如下所示：

```http
https://192.168.68.11:30001/
```

进入到登录页面后，需要填写用户token，填写完成后，直接登录即可：

![image-20210306010103826](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210306010108.png) 

下面就是登录成功后的主界面：

![image-20210306010249999](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210306010255.png) 

### 3.k8s的命令行工具kubectl

kubectl是Kubernetes集群的命令行工具，通过kubectl能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署。

#### 3.1 基本语法

```shell
kubectl [command] [TYPE] [NAME] [flags]
```

- `command`：指定要对一个或多个资源执行的操作，例如 ==create==、==get==、==describe==、==delete==。

- `TYPE`：指定资源类型，资源类型不区分大小写，可以指定单数、复数或缩写形式。例如，以下命令输出的结果相同:

```shell
kubectl get pod pod1
kubectl get pods pod1
kubectl get po pod1
```

- `NAME`：指定资源的名称，名称区分大小写。如果省略名称，可以使用`kubectl get pods`显示所有资源的详细信息。
- `flags`：指定可选的参数。例如，可以使用`-s`或`-server`参数指定Kubernetes API服务器的地址和端口。

#### 3.2 kubectl子命令使用分类

##### 基础命令：

![image-20210314173053517](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210314173506.png) 

##### 部署和集群管理命令：

![image-20210314173233468](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210314173515.png) 

##### 故障诊断和调试命令：

![image-20210314173354442](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210314173524.png) 

##### 其他命令：

![image-20210314173434052](https://cdn.jsdelivr.net/gh/gongcqq/FigureBed@main/Image/Typora/20210314173542.png) 

### 4.资源清单详解

k8s集群中对资源管理和资源对象编排部署都可以通过声明样式(YAML)文件来解决，也就是可以把需要对资源对象的操作编辑到YAML格式文件中，我们把这种文件叫做资源清单文件，通过kubectl命令直接操作资源清单文件就可以实现对大量的资源对象进行编排部署。

在k8s中，一般使用YAML格式的文件来创建符合我们预期期望的pod,这样的YAML文件称为资源清单。

#### 4.1 资源清单中的常用字段

##### 4.1.1 必须存在的属性

| 参数名                  | 字段类型 | 说明                                                         |
| ----------------------- | -------- | ------------------------------------------------------------ |
| version                 | String   | K8S API的版本，目前基本是v1，可以使用`kubectl api-versions`命令进行查询 |
| kind                    | String   | 这里指的是yaml文件定义的资源类型和角色，比如：Deployment     |
| metadata                | Object   | 元数据对象，固定值，不可更改                                 |
| metadata.name           | String   | 元数据对象的名称，由我们自定义                               |
| metadata.namespace      | String   | 元数据对象的命名空间，由我们自定义，默认值是default          |
| spec                    | Object   | 详细定义对象，固定值，不可更改                               |
| spec.containers[]       | list     | 这里是spec对象的容器列表定义，是个列表                       |
| spec.containers[].name  | String   | 这里定义容器的名称                                           |
| spec.containers[].image | String   | 这里定义要用到的镜像的名称                                   |

##### 4.1.2 spec的主要属性

| 参数名                                      | 字段类型 | 说明                                                         |
| :------------------------------------------ | :------- | :----------------------------------------------------------- |
| spec.containers[].name                      | String   | 用于定义容器的名称                                           |
| spec.containers[].image                     | String   | 用于定义要用到的镜像的名称                                   |
| spec.containers[].imagePullPolicy           | String   | 定义镜像的拉取策略，有`Always`，`Never`，`IfNotPresent`三种策略可选。Always意思是每次都尝试重新拉取镜像；Never指的是仅使用本地镜像；IfNotPresent指的是如果本地有镜像就使用本地镜像，没有就拉取在线镜像。如果没有设置策略的话，默认使用的是Always。 |
| spec.containers[].command[]                 | List     | 指定容器的启动命令，可以指定多个。不指定则使用镜像打包时使用的启动命令。 |
| spec.containers[].args[]                    | List     | 指定容器的启动命令参数，可以指定多个                         |
| spec.containers[].workingDir                | String   | 指定容器的工作目录                                           |
| spec.containers[].volumeMounts[]            | List     | 指定容器内部的存储卷配置                                     |
| spec.containers[].volumeMounts[].name       | String   | 指定可以被容器挂载的存储卷的名称                             |
| spec.containers[].volumeMounts[].mountPath  | String   | 指定可以被容器挂载的存储卷的路径                             |
| spec.containers[].volumeMounts[].readOnly   | String   | 设置存储卷路径读写的模式，true或者false，默认为读写模式。    |
| spec.containers[].ports[]                   | List     | 指定容器需要用到的端口列表                                   |
| spec.containers[].ports[].name              | String   | 指定端口名称                                                 |
| spec.containers[].ports[].containerPort     | String   | 指定容器需要监听的端口号                                     |
| spec.containers[].ports[].hostPost          | String   | 指定容器所在主机需要监听的端口号，默认跟上面containerPort相同。需要注意，设置了hostPost同一台主机无法启动该容器的相同副本(因为主机的端口号不能相同，这样会冲突)。 |
| spec.containers[].ports[].protocol          | String   | 指定端口协议，支持TCP和UDP，默认值为TCP                      |
| spec.containers[].env[]                     | List     | 指定容器运行时需要设置的环境变量列表                         |
| spec.containers[].env[].name                | String   | 指定环境变量名称                                             |
| spec.containers[].env[].value               | String   | 指定环境变量值                                               |
| spec.containers[].resources                 | Object   | 指定资源限制和资源请求的值                                   |
| spec.containers[].resources.limits          | Object   | 指定设置容器运行时资源的运行上限                             |
| spec.containers[].resources.limits.cpu      | String   | 指定CPU的限制                                                |
| spec.containers[].resources.limits.memory   | String   | 指定MEM内存的限制                                            |
| spec.containers[].resources.requests        | Object   | 指定容器启动和调度室的限制设置                               |
| spec.containers[].resources.requests.cpu    | String   | CPU请求，容器启动时初始化的可用数量                          |
| spec.containers[].resources.requests.memory | String   | 内存请求，容器启动时初始化的可用数量                         |
| spec.restartPolicy                          | String   | 定义Pod重启策略，可以选择值为`Always`、`OnFailure`、`Never`，默认值为Always。使用Always表示Pod一旦终止运行，无论容器是如何终止的，kubelet服务都将重启它；OnFailure表示只有Pod以非零退出码终止时，kubelet才会重启该容器，如果容器是正常结束(退出码为0)，则kubelet将不会重启它；Never表示Pod终止后，kubelet会将退出码报告给Master，但不会重启该Pod。 |
| spec.nodeSelector                           | Object   | 定义Node的Label过滤标签，以key:value格式指定。               |
| spec.imagePullSecrets                       | Object   | 定义pull镜像时使用secret名称，以name:secretkey格式指定。     |

#### 4.2 举例说明

##### 4.2.1 查看已有资源的资源详情

以Deployment的资源清单为例，命令如下：

```shell
#查看有哪些Deployment资源
kubectl get deploy -o wide

#根据名称获取资源清单详情，下面的"harbor-test"就是Deployment的名称
kubectl get deploy harbor-test -o yaml
```

获取到的资源清单详情如下：

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
  creationTimestamp: "2020-09-29T08:57:26Z"
  generation: 1
  name: harbor-test
  namespace: default
  resourceVersion: "56211880"
  selfLink: /apis/extensions/v1beta1/namespaces/default/deployments/harbor-test
  uid: 38711c5c-b616-4cb8-906f-24b8cb7a5729
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: harbor
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: harbor
      name: harbor-test
    spec:
      containers:
      - image: ai/pushgateway:v0.8.0
        imagePullPolicy: IfNotPresent
        name: harbor-test
        ports:
        - containerPort: 9090
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 1
  conditions:
  - lastTransitionTime: "2020-09-29T08:57:26Z"
    lastUpdateTime: "2020-09-29T08:57:31Z"
    message: ReplicaSet "harbor-test-7864497b8f" has successfully progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  - lastTransitionTime: "2021-04-08T02:00:10Z"
    lastUpdateTime: "2021-04-08T02:00:10Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  observedGeneration: 1
  readyReplicas: 1
  replicas: 1
  updatedReplicas: 1
```

##### 4.2.2 查看新建资源的资源详情

如果之前并没有已经存在的资源，我们也可以新建一个资源，并查看其资源清单详情。

以Deployment的资源清单为例，命令如下：

```shell
#该命令意思就是新建一个名为"gongsl"的Deployment资源
kubectl create deploy gongsl --image=nginx:1.17 -o yaml --dry-run=client
```

获取到的资源清单详情如下：

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: gongsl
  name: gongsl
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gongsl
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: gongsl
    spec:
      containers:
      - image: nginx:1.17
        name: nginx
        resources: {}
status: {}
```

**注意事项：**

1. 上面新建资源使用的命令后面加上的`--dry-run=client`表示尝试运行，也就是说，加上这个后，并不会真的新建一个Deployment资源，只是模拟一下这个效果，如果想要真的新建一个Deployment资源的话，去掉它即可；
2. 低版本的k8s中，想要尝试运行的话，命令后面加的并不是`--dry-run=client`，而是`--dry-run`。

### 5.Pod













